{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595ac845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c683b24",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921933e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [0, 1, 2, 3]  # up, down, left, right\n",
    "states = [i for i in range(0, 54)]\n",
    "barrier_states = [7, 11, 16, 20, 25, 29, 41]\n",
    "goal_state = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea094df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def environment(s, a):\n",
    "    if s == goal_state:\n",
    "        return (s, 0)\n",
    "    if s in barrier_states:\n",
    "        return (-10, -10)\n",
    "    \n",
    "    #-------- up ---------\n",
    "    if a == 0:\n",
    "        ns = s - 9  # next state\n",
    "        if (ns < 0) or (ns in barrier_states):\n",
    "            return (s, -1)\n",
    "        elif ns == goal_state:\n",
    "            return (ns, 1)\n",
    "        else:\n",
    "            return (ns, 0)\n",
    "                        \n",
    "    #-------- down ---------    \n",
    "    if a == 1: \n",
    "        ns = s + 9  # next state\n",
    "        if (ns > 53) or (ns in barrier_states):\n",
    "            return (s, -1)  \n",
    "        else:\n",
    "            return (ns, 0)\n",
    "\n",
    "    #-------- left ---------    \n",
    "    if a == 2: \n",
    "        ns = s - 1  # next state\n",
    "        if (ns % 9 == 8) or (ns < 0) or (ns in barrier_states):\n",
    "            return (s, -1)  \n",
    "        else:\n",
    "            return (ns, 0)\n",
    "\n",
    "    #-------- right ---------    \n",
    "    if a == 3:\n",
    "        ns = s + 1  # next state\n",
    "        if (ns % 9 == 0) or (ns in barrier_states):\n",
    "            return (s, -1)  \n",
    "        elif ns == goal_state:\n",
    "            return (ns, 1)\n",
    "        else:\n",
    "            return (ns, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c17f05",
   "metadata": {},
   "source": [
    "# Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de68dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_selection(state, Q):  # assume greedy policy\n",
    "    action = np.random.choice(np.flatnonzero(Q[state] == Q[state].max()))   # choose randomly from maximum values   \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ba5b3",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea9fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9  # discount factor\n",
    "alpha = 0.01  # learning rate\n",
    "episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ef0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_learning(Q):\n",
    "    for e in range(episodes):\n",
    "        s = random.randint(0, 53)  # start from random state\n",
    "\n",
    "        while s != goal_state:\n",
    "            a = action_selection(s, Q)\n",
    "\n",
    "            (ns, r) = environment(s, a)   # next state and reward\n",
    "            # to avoid starting from obstacle cell\n",
    "            while ns == -10 and r == -10:  \n",
    "                s = random.randint(0, 53)\n",
    "                a = action_selection(s, Q)\n",
    "                (ns, r) = environment(s, a)\n",
    "\n",
    "            Q[s][a] = Q[s][a] + alpha * (r + gamma * max(Q[ns]) - Q[s][a])\n",
    "            s = ns\n",
    "\n",
    "    policy = np.array([0]*54)\n",
    "    for state in states:\n",
    "        policy[state] = np.argmax(Q[state])\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc3baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy: [3 3 3 3 1 1 1 0 0 3 0 0 3 1 1 1 0 0 0 0 0 3 3 3 1 0 0 3 0 0 0 0 3 3 3 0 0\n",
      " 0 3 3 0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "random.seed(10)\n",
    "Q = np.array([[0.] * len(actions)] * len(states))\n",
    "\n",
    "policy = Q_learning(Q)\n",
    "print('Optimal policy:', policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
